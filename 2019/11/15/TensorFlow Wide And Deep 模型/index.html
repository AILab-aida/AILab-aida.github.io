<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.png?v=7.4.0">
  <link rel="mask-icon" href="/images/safari-pinned-tab.svg?v=7.4.0" color="#222">
  <link rel="alternate" href="/atom.xml" title="AILab-aida" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":"mac"},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: true,
    lazyload: false,
    pangu: true,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="之前对 Wide And Deep 模型看过一点文章，但是没有深入了解，这两天抽出时间来仔细看了下相关代码和资料，然后写点初步的总结，总体来说还是很有意思的想法，把深度学习突破了在图像和语言领域的限制，用到了以往机器学习的领域，并且取得了更好的结果。核心思想是？ wide and deep 模型的核心思想是结合线性模型的记忆能力（memorization）和 DNN 模型的泛化能力（general">
<meta name="keywords" content="算法">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow Wide And Deep 模型">
<meta property="og:url" content="https://ailab-aida.github.io/2019/11/15/TensorFlow Wide And Deep 模型/index.html">
<meta property="og:site_name" content="AILab-aida">
<meta property="og:description" content="之前对 Wide And Deep 模型看过一点文章，但是没有深入了解，这两天抽出时间来仔细看了下相关代码和资料，然后写点初步的总结，总体来说还是很有意思的想法，把深度学习突破了在图像和语言领域的限制，用到了以往机器学习的领域，并且取得了更好的结果。核心思想是？ wide and deep 模型的核心思想是结合线性模型的记忆能力（memorization）和 DNN 模型的泛化能力（general">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-11-15T07:24:21.192Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="TensorFlow Wide And Deep 模型">
<meta name="twitter:description" content="之前对 Wide And Deep 模型看过一点文章，但是没有深入了解，这两天抽出时间来仔细看了下相关代码和资料，然后写点初步的总结，总体来说还是很有意思的想法，把深度学习突破了在图像和语言领域的限制，用到了以往机器学习的领域，并且取得了更好的结果。核心思想是？ wide and deep 模型的核心思想是结合线性模型的记忆能力（memorization）和 DNN 模型的泛化能力（general">
  <link rel="canonical" href="https://ailab-aida.github.io/2019/11/15/TensorFlow Wide And Deep 模型/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>TensorFlow Wide And Deep 模型 | AILab-aida</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">AILab-aida</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">一个专注技术的组织</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-sitemap">
      
    

    <a href="/atom.xml" rel="section"><i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br>地图</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>

  <a href="https://github.com/qq1074123922" class="github-corner" title="AILab-aida GitHub" aria-label="AILab-aida GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://ailab-aida.github.io/2019/11/15/TensorFlow Wide And Deep 模型/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="AILab-aida">
      <meta itemprop="description" content="涉猎的主要编程语言为 深度学习、机器学习、大数据、服务端、移动端、前端、爬虫(go、scala、Java、flutter、Python、react、Vue)等。">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="AILab-aida">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">TensorFlow Wide And Deep 模型

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-11-15 15:04:28 / 修改时间：15:24:21" itemprop="dateCreated datePublished" datetime="2019-11-15T15:04:28+08:00">2019-11-15</time>
            </span>
          
            

            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>之前对 Wide And Deep 模型看过一点文章，但是没有深入了解，这两天抽出时间来仔细看了下相关代码和资料，然后写点初步的总结，总体来说还是很有意思的想法，把深度学习突破了在图像和语言领域的限制，用到了以往机器学习的领域，并且取得了更好的结果。</p><h2 id="核心思想是？"><a href="#核心思想是？" class="headerlink" title="核心思想是？"></a><strong>核心思想是？</strong></h2><blockquote>
<p>wide and deep 模型的核心思想是结合线性模型的记忆能力（memorization）和 DNN 模型的泛化能力（generalization），在训练过程中同时优化两个模型的参数，从而达到整体模型的预测能力最优。</p>
</blockquote><a id="more"></a>

<h2 id="模型的特征构建与以往的线性模型、神经网络模型比较有什么特点？"><a href="#模型的特征构建与以往的线性模型、神经网络模型比较有什么特点？" class="headerlink" title="模型的特征构建与以往的线性模型、神经网络模型比较有什么特点？"></a><strong>模型的特征构建与以往的线性模型、神经网络模型比较有什么特点？</strong></h2><p>特征的种类如下：</p>
<p>（第一行是 contrib 模块的 API，下面一行是正式的 API）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">tf.contrib.layers.real_valued_column 或者</span><br><span class="line">tf.feature_column.numeric_column</span><br><span class="line">连续数值特征</span><br><span class="line"></span><br><span class="line">tf.contrib.layers.sparse_column_with_keys 或者</span><br><span class="line">tf.feature_column.categorical_column_with_vocabulary_list</span><br><span class="line">按照自定义的字典将类别特征映射到数值，适合特征种类较少时候使用</span><br><span class="line"></span><br><span class="line">tf.contrib.layers.sparse_column_with_hash_bucket  或者</span><br><span class="line">tf.feature_column.categorical_column_with_hash_bucket</span><br><span class="line">自动将类别特征映射到数值，适合特征种类较多时候使用</span><br><span class="line"></span><br><span class="line">tf.contrib.layers.bucketized_column  或者</span><br><span class="line">tf.feature_column.bucketized_column</span><br><span class="line">把连续特征按照区间映射为类别特征</span><br><span class="line"></span><br><span class="line">tf.contrib.layers.crossed_column   或者</span><br><span class="line">tf.feature_column.crossed_column</span><br><span class="line">特征相乘生成的交叉特征</span><br></pre></td></tr></table></figure>
<p>可以看到，特征的种类还是类似于以往的机器学习领域的特征，以往做过机器学习项目的会比较熟悉，与图像语音等领域的还是有较大区别。</p>
<h2 id="离散的特征怎么传入神经网络模型？"><a href="#离散的特征怎么传入神经网络模型？" class="headerlink" title="离散的特征怎么传入神经网络模型？"></a><strong>离散的特征怎么传入神经网络模型？</strong></h2><p>连续的特征可以直接传入神经网络，但是离散的特征需要做处理之后再传入：</p>
<blockquote>
<p>To feed sparse features into DNN models, wrap the column with <code>embedding_column</code> or <code>one_hot_column</code>. <code>one_hot_column</code> will create a dense boolean tensor with an entry for each possible value, and thus the computation cost is linear in the number of possible values versus the number of values that occur in the sparse tensor. Thus using a “one_hot_column” is only recommended for features with only a few possible values. For features with many possible values or for very sparse features, <code>embedding_column</code> is recommended.</p>
</blockquote>
<p>有两种方式进行处理，<strong>可以使用 one-hot 编码处理神经网络输入的离散特征，也可以使用 embedding 处理</strong>；</p>
<p>建议该特征的数值种类较少时候使用 one-hot 编码，在该特征的数值种类较多的情况下使用 embedding 编码，这里之所以要这么处理，我理解的原因是独热编码如果数值种类很多，会导致编码后的特征维度太高，从而学习到的信息过于分散，因此，在种类很多的时候，需要先将超高维的种类离散特征进行压缩 embedding, 再送入神经网络；</p>
<p>那么，究竟什么是 embedding 处理呢？</p>
<h2 id="什么是-embedding-column-？-什么时候使用？"><a href="#什么是-embedding-column-？-什么时候使用？" class="headerlink" title="什么是 embedding_column ？ 什么时候使用？"></a><strong>什么是 embedding_column ？ 什么时候使用？</strong></h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">embedding_weights = variable_scope.get_variable(</span><br><span class="line"> name=&apos;embedding_weights&apos;,</span><br><span class="line"> shape=(self.categorical_column._num_buckets, self.dimension), # pylint: disable=protected-access</span><br><span class="line"> dtype=dtypes.float32,</span><br><span class="line"> initializer=self.initializer,</span><br><span class="line"> trainable=self.trainable and trainable)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>这是把离散特征 embedding 操作的核心，它把原始的类别数值映射到这个权值矩阵，其实相当于神经网络的权值，后续如果是 trainable 的话，我们就会把这个当做网络的权值矩阵进行训练，但是在用的时候，就把这个当成一个 embedding 表，按 id 去取每个特征的 embedding 后的数值。（这其实就类似于词向量了，把每个单词映射到一个词向量。）</p>
</blockquote>
<h2 id="什么是-sparseTensor？-什么时候使用这种数据类型？"><a href="#什么是-sparseTensor？-什么时候使用这种数据类型？" class="headerlink" title="什么是 sparseTensor？ 什么时候使用这种数据类型？"></a><strong>什么是</strong> <strong>sparseTensor？</strong> <strong>什么时候使用这种数据类型？</strong></h2><p>它是用（位置，值，形状） 三个元素简略的表示一个矩阵的方法，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SparseTensor(indices=[[0, 0], [1, 2]], values=[1, 2], dense_shape=[3, 4])</span><br></pre></td></tr></table></figure>
<p>表示如下矩阵：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[[1, 0, 0, 0]</span><br><span class="line"> [0, 0, 2, 0]</span><br><span class="line">[0, 0, 0, 0]]</span><br></pre></td></tr></table></figure>
<p>也就是说它表明，在（0，0）的位置有 1， （1，2）的位置存在 2；</p>
<p>它<strong>只针对类别特征，适合于表示矩阵中大量元素为 0 的情况</strong>，会大大减少矩阵占用的存储量；在案例中，我发现它经常用来作为一个类别特征的中间变量矩阵，用来减小内存占用，例如：</p>
<p>这个代码中把所有的类别变量都用 SparseTensor 做了一个转换：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">categorical_cols = &#123;k: tf.SparseTensor(</span><br><span class="line">                    indices=[[i,0] for i in range( df[k].size)],</span><br><span class="line">                    values = df[k].values,    # 三个元素</span><br><span class="line">                    shape=[df[k].size,1])</span><br><span class="line">                    for k in CATEGORICAL_COLUMNS&#125;</span><br></pre></td></tr></table></figure>
<p>值得注意的是，<strong>sparseTensor 本质上还是一个矩阵，它只是把矩阵用另外一种形式来表示了。</strong></p>
<p><strong>两个模型使用不同的优化器是什么？ 怎么在 loss 层面配合？</strong></p>
<p>以 tf.estimator.DNNLinearCombinedClassifier() 为例，进入该函数发现：linear_optimizer=’Ftrl’, 线性模型使用’Ftrl’优化器，</p>
<p>dnn_optimizer=’Adagrad’, 神经网络使用’Adagrad’优化器；</p>
<p>如果分类数量是 2，loss 使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_binary_logistic_head_with_sigmoid_cross_entropy_loss</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nn.sigmoid_cross_entropy_with_logits(labels=labels, logits=logits, name=&apos;loss&apos;)</span><br></pre></td></tr></table></figure>
<p>如果分类数量大于 2，loss 使用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">_multi_class_head_with_softmax_cross_entropy_loss</span><br></pre></td></tr></table></figure>
<p>调用</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">losses.sparse_softmax_cross_entropy(labels=label_ids,</span><br><span class="line">                 logits=logits, reduction=losses.Reduction.NONE)</span><br></pre></td></tr></table></figure>
<p><strong>最后怎么得到两个模型结合的预测结果的？</strong></p>
<p>直接把两个模型的结果相加：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">logits = dnn_logits + linear_logits</span><br></pre></td></tr></table></figure>
<p>很出乎意料的方式啊，居然是直接相加的，然后是上面一点提到的操作，用这个 logits 和 label 得到 Loss，再将 Loss 分别反传回两个独立的优化器分别优化两个模型的权重。</p>
<p><strong>两个模型各自使用的特征是什么？</strong></p>
<p>先看代码：</p>
<p>离散特征和连续特征分别如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 类别特征</span><br><span class="line">CATEGORICAL_COLUMNS = [&quot;workclass&quot;, &quot;education&quot;, &quot;marital_status&quot;, &quot;occupation&quot;,</span><br><span class="line">                       &quot;relationship&quot;, &quot;race&quot;, &quot;gender&quot;, &quot;native_country&quot;]</span><br><span class="line"># 连续特征</span><br><span class="line">CONTINUOUS_COLUMNS = [&quot;age&quot;, &quot;education_num&quot;, &quot;capital_gain&quot;, &quot;capital_loss&quot;,</span><br><span class="line">                      &quot;hours_per_week&quot;]</span><br></pre></td></tr></table></figure>
<p>两个模块对特征的使用情况如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">wide_columns = [gender, native_country,education, occupation, workclass, relationship, age_buckets,</span><br><span class="line">                tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4)),</span><br><span class="line">                tf.contrib.layers.crossed_column([age_buckets, education, occupation], hash_bucket_size=int(1e6)),</span><br><span class="line">                tf.contrib.layers.crossed_column([native_country, occupation],hash_bucket_size=int(1e4))]</span><br><span class="line"></span><br><span class="line">#embedding_column用来表示类别型的变量</span><br><span class="line">deep_columns = [tf.contrib.layers.embedding_column(workclass, dimension=8),</span><br><span class="line">                tf.contrib.layers.embedding_column(education, dimension=8),</span><br><span class="line">                tf.contrib.layers.embedding_column(gender, dimension=8),</span><br><span class="line">                tf.contrib.layers.embedding_column(relationship, dimension=8),</span><br><span class="line">                tf.contrib.layers.embedding_column(native_country,dimension=8),</span><br><span class="line">                tf.contrib.layers.embedding_column(occupation, dimension=8),</span><br><span class="line">                age,education_num,capital_gain,capital_loss,hours_per_week,]</span><br></pre></td></tr></table></figure>
<p>wide 模型的特征都是离散特征、 离散特征之间的交互作用特征；</p>
<p>deep 模型的特征则是离散特征 embedding 加上连续特征；</p>
<p>wide 端模型和 deep 端模型只需要分别专注于擅长的方面，wide 端模型通过离散特征的交叉组合进行 memorization，deep 端模型通过特征的 embedding 进行 generalization，这样单个模型的大小和复杂度也能得到控制，而整体模型的性能仍能得到提高。</p>
<p>但是这种做法是不是一定要遵循，连续特征是否一定不要放入线性模型中去？我认为不一定，在以往的线性模型建模中，连续特征也是起到了很大作用的，所以可以在实践中进行尝试，不一定非得遵循这种做法。</p>
<h2 id="几点疑问："><a href="#几点疑问：" class="headerlink" title="几点疑问："></a>几点疑问：</h2><ul>
<li>所有的输入到 deep 端 DNN 的连续特征都没有做归一化的处理？</li>
<li>报错 InternalError (see above for traceback): Blas GEMM launch failed : a.shape=(1282, 53), b.shape=(53, 100), m=1282, n=100, k=53 无法解决，网上查资料说是因为 GPU 内存不够，但即便把数据量调整到很小后还是报错，如果有人碰到这个问题的还希望留言答疑。</li>
<li>无法查看 bucketized_column，sparse_column_with_hash_bucket 等处理之后的特征数值，调用该 API 后只是定义了该特征列，无法看到它的实际数值。</li>
</ul>
<p>相关代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br></pre></td><td class="code"><pre><span class="line">import tempfile</span><br><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line">from six.moves import urllib</span><br><span class="line"></span><br><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">flags = tf.app.flags</span><br><span class="line">FLAGS = flags.FLAGS</span><br><span class="line"></span><br><span class="line">flags.DEFINE_string(&quot;model_dir&quot;,&quot;&quot;,&quot;Base directory for output models.&quot;)</span><br><span class="line">flags.DEFINE_string(&quot;model_type&quot;,&quot;wide_n_deep&quot;,&quot;valid model types:&#123;&apos;wide&apos;,&apos;deep&apos;, &apos;wide_n_deep&apos;&quot;)</span><br><span class="line">flags.DEFINE_integer(&quot;train_steps&quot;,200,&quot;Number of training steps.&quot;)</span><br><span class="line">flags.DEFINE_string(&quot;train_data&quot;,&quot;&quot;, &quot;Path to the training data.&quot;)</span><br><span class="line">flags.DEFINE_string(&quot;test_data&quot;, &quot;&quot;, &quot;path to the test data&quot;)</span><br><span class="line"></span><br><span class="line">COLUMNS = [&quot;age&quot;, &quot;workclass&quot;, &quot;fnlwgt&quot;, &quot;education&quot;, &quot;education_num&quot;,</span><br><span class="line">           &quot;marital_status&quot;, &quot;occupation&quot;, &quot;relationship&quot;, &quot;race&quot;, &quot;gender&quot;,</span><br><span class="line">           &quot;capital_gain&quot;, &quot;capital_loss&quot;, &quot;hours_per_week&quot;, &quot;native_country&quot;,</span><br><span class="line">           &quot;income_bracket&quot;]</span><br><span class="line"></span><br><span class="line">LABEL_COLUMN = &quot;label&quot;</span><br><span class="line"></span><br><span class="line">CATEGORICAL_COLUMNS = [&quot;workclass&quot;, &quot;education&quot;, &quot;marital_status&quot;, &quot;occupation&quot;,</span><br><span class="line">                       &quot;relationship&quot;, &quot;race&quot;, &quot;gender&quot;, &quot;native_country&quot;]</span><br><span class="line"></span><br><span class="line">CONTINUOUS_COLUMNS = [&quot;age&quot;, &quot;education_num&quot;, &quot;capital_gain&quot;, &quot;capital_loss&quot;,</span><br><span class="line">                      &quot;hours_per_week&quot;]</span><br><span class="line"></span><br><span class="line"># download test and train data</span><br><span class="line">def maybe_download():</span><br><span class="line">    if FLAGS.train_data:</span><br><span class="line">        train_data_file = FLAGS.train_data</span><br><span class="line">    else:</span><br><span class="line">        train_file = tempfile.NamedTemporaryFile(delete=False)</span><br><span class="line">        urllib.request.urlretrieve(&quot;http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.data&quot;, train_file.name)</span><br><span class="line">        train_file_name = train_file.name</span><br><span class="line">        train_file.close()</span><br><span class="line">        print(&quot;Training data is downloaded to %s&quot; % train_file_name)</span><br><span class="line"></span><br><span class="line">    if FLAGS.test_data:</span><br><span class="line">        test_file_name = FLAGS.test_data</span><br><span class="line">    else:</span><br><span class="line">        test_file = tempfile.NamedTemporaryFile(delete=False)</span><br><span class="line">        urllib.request.urlretrieve(&quot;http://mlr.cs.umass.edu/ml/machine-learning-databases/adult/adult.test&quot;,</span><br><span class="line">                                   test_file.name)  # pylint: disable=line-too-long</span><br><span class="line">        test_file_name = test_file.name</span><br><span class="line">        test_file.close()</span><br><span class="line">        print(&quot;Test data is downloaded to %s&quot; % test_file_name)</span><br><span class="line"></span><br><span class="line">    return train_file_name, test_file_name</span><br><span class="line"></span><br><span class="line"># build the estimator</span><br><span class="line">def build_estimator(model_dir):</span><br><span class="line">    # 离散分类别的</span><br><span class="line">    gender = tf.contrib.layers.sparse_column_with_keys(column_, keys=[&quot;female&quot;,&quot;male&quot;])</span><br><span class="line">    education = tf.contrib.layers.sparse_column_with_hash_bucket(&quot;education&quot;, hash_bucket_size = 1000)</span><br><span class="line">    relationship = tf.contrib.layers.sparse_column_with_hash_bucket(&quot;relationship&quot;, hash_bucket_size = 100)</span><br><span class="line">    workclass = tf.contrib.layers.sparse_column_with_hash_bucket(&quot;workclass&quot;, hash_bucket_size=100)</span><br><span class="line">    occupation = tf.contrib.layers.sparse_column_with_hash_bucket(&quot;occupation&quot;, hash_bucket_size=1000)</span><br><span class="line">    native_country = tf.contrib.layers.sparse_column_with_hash_bucket( &quot;native_country&quot;, hash_bucket_size=1000)</span><br><span class="line"></span><br><span class="line">    # Continuous base columns.</span><br><span class="line">    age = tf.contrib.layers.real_valued_column(&quot;age&quot;)</span><br><span class="line">    education_num = tf.contrib.layers.real_valued_column(&quot;education_num&quot;)</span><br><span class="line">    capital_gain = tf.contrib.layers.real_valued_column(&quot;capital_gain&quot;)</span><br><span class="line">    capital_loss = tf.contrib.layers.real_valued_column(&quot;capital_loss&quot;)</span><br><span class="line">    hours_per_week = tf.contrib.layers.real_valued_column(&quot;hours_per_week&quot;)</span><br><span class="line">    #类别转换</span><br><span class="line">    age_buckets = tf.contrib.layers.bucketized_column(age, boundaries= [18,25, 30, 35, 40, 45, 50, 55, 60, 65])</span><br><span class="line"></span><br><span class="line">    wide_columns = [gender, native_country,education, occupation, workclass, relationship, age_buckets,</span><br><span class="line">                    tf.contrib.layers.crossed_column([education, occupation], hash_bucket_size=int(1e4)),</span><br><span class="line">                    tf.contrib.layers.crossed_column([age_buckets, education, occupation], hash_bucket_size=int(1e6)),</span><br><span class="line">                    tf.contrib.layers.crossed_column([native_country, occupation],hash_bucket_size=int(1e4))]</span><br><span class="line"></span><br><span class="line">    #embedding_column用来表示类别型的变量</span><br><span class="line">    deep_columns = [tf.contrib.layers.embedding_column(workclass, dimension=8),</span><br><span class="line">                    tf.contrib.layers.embedding_column(education, dimension=8),</span><br><span class="line">                    tf.contrib.layers.embedding_column(gender, dimension=8),</span><br><span class="line">                    tf.contrib.layers.embedding_column(relationship, dimension=8),</span><br><span class="line">                    tf.contrib.layers.embedding_column(native_country,dimension=8),</span><br><span class="line">                    tf.contrib.layers.embedding_column(occupation, dimension=8),</span><br><span class="line">                    age,education_num,capital_gain,capital_loss,hours_per_week,]</span><br><span class="line"></span><br><span class="line">    if FLAGS.model_type ==&quot;wide&quot;:</span><br><span class="line">        m = tf.contrib.learn.LinearClassifier(model_dir=model_dir,feature_columns=wide_columns)</span><br><span class="line">    elif FLAGS.model_type == &quot;deep&quot;:</span><br><span class="line">        m = tf.contrib.learn.DNNClassifier(model_dir=model_dir, feature_columns=deep_columns, hidden_units=[100,50])</span><br><span class="line">    else:</span><br><span class="line">        m = tf.contrib.learn.DNNLinearCombinedClassifier(model_dir=model_dir, linear_feature_columns=wide_columns, dnn_feature_columns = deep_columns, dnn_hidden_units=[100,50])</span><br><span class="line"></span><br><span class="line">    return m</span><br><span class="line"></span><br><span class="line">def input_fn(df):</span><br><span class="line">    continuous_cols = &#123;k: tf.constant(df[k].values) for k in CONTINUOUS_COLUMNS&#125;</span><br><span class="line">    categorical_cols = &#123;k: tf.SparseTensor(indices=[[i,0] for i in range( df[k].size)], values = df[k].values, shape=[df[k].size,1]) for k in CATEGORICAL_COLUMNS&#125;#原文例子为dense_shape</span><br><span class="line">    feature_cols = dict(continuous_cols)</span><br><span class="line">    feature_cols.update(categorical_cols)</span><br><span class="line">    label = tf.constant(df[LABEL_COLUMN].values)</span><br><span class="line"></span><br><span class="line">    return feature_cols, label</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def train_and_eval():</span><br><span class="line">    train_file_name, test_file_name = maybe_download()</span><br><span class="line">    df_train = pd.read_csv(</span><br><span class="line">        tf.gfile.Open(train_file_name),</span><br><span class="line">        names=COLUMNS,</span><br><span class="line">        skipinitialspace=True,</span><br><span class="line">        engine=&quot;python&quot;</span><br><span class="line">    )</span><br><span class="line">    df_test = pd.read_csv(</span><br><span class="line">        tf.gfile.Open(test_file_name),</span><br><span class="line">        names=COLUMNS,</span><br><span class="line">        skipinitialspace=True,</span><br><span class="line">        skiprows=1,</span><br><span class="line">        engine=&quot;python&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    # drop Not a number elements</span><br><span class="line">    df_train = df_train.dropna(how=&apos;any&apos;,axis=0)</span><br><span class="line">    df_test = df_test.dropna(how=&apos;any&apos;, axis=0)</span><br><span class="line"></span><br><span class="line">    #convert &gt;50 to 1</span><br><span class="line">    df_train[LABEL_COLUMN] = (</span><br><span class="line">        df_train[&quot;income_bracket&quot;].apply(lambda x: &quot;&gt;50&quot; in x).astype(int)</span><br><span class="line">    )</span><br><span class="line">    df_test[LABEL_COLUMN] = (</span><br><span class="line">        df_test[&quot;income_bracket&quot;].apply(lambda x: &quot;&gt;50K&quot; in x)).astype(int)</span><br><span class="line"></span><br><span class="line">    model_dir = tempfile.mkdtemp() if not FLAGS.model_dir else FLAGS.model_dir</span><br><span class="line">    print(&quot;model dir = %s&quot; % model_dir)</span><br><span class="line"></span><br><span class="line">    m = build_estimator(model_dir)</span><br><span class="line">    print (FLAGS.train_steps)</span><br><span class="line">    m.fit(input_fn=lambda: input_fn(df_train),</span><br><span class="line">          steps=FLAGS.train_steps)</span><br><span class="line">    results = m.evaluate(input_fn=lambda: input_fn(df_test), steps=1)</span><br><span class="line"></span><br><span class="line">    for key in sorted(results):</span><br><span class="line">        print(&quot;%s: %s&quot;%(key, results[key]))</span><br><span class="line"></span><br><span class="line">def main(_):</span><br><span class="line">  train_and_eval()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">  tf.app.run()</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        
      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>AILab-aida</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://ailab-aida.github.io/2019/11/15/TensorFlow Wide And Deep 模型/" title="TensorFlow Wide And Deep 模型">https://ailab-aida.github.io/2019/11/15/TensorFlow Wide And Deep 模型/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/算法/" rel="tag"># 算法</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/11/15/向量搜索的简明数学基础/" rel="next" title="向量搜索的简明数学基础">
                  <i class="fa fa-chevron-left"></i> 向量搜索的简明数学基础
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/11/15/ernie实战/" rel="prev" title="PAI ernie实战">
                  PAI ernie实战 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#核心思想是？"><span class="nav-number">1.</span> <span class="nav-text">核心思想是？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型的特征构建与以往的线性模型、神经网络模型比较有什么特点？"><span class="nav-number">2.</span> <span class="nav-text">模型的特征构建与以往的线性模型、神经网络模型比较有什么特点？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#离散的特征怎么传入神经网络模型？"><span class="nav-number">3.</span> <span class="nav-text">离散的特征怎么传入神经网络模型？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是-embedding-column-？-什么时候使用？"><span class="nav-number">4.</span> <span class="nav-text">什么是 embedding_column ？ 什么时候使用？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#什么是-sparseTensor？-什么时候使用这种数据类型？"><span class="nav-number">5.</span> <span class="nav-text">什么是 sparseTensor？ 什么时候使用这种数据类型？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#几点疑问："><span class="nav-number">6.</span> <span class="nav-text">几点疑问：</span></a></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/avatar.png"
      alt="AILab-aida">
  <p class="site-author-name" itemprop="name">AILab-aida</p>
  <div class="site-description" itemprop="description">涉猎的主要编程语言为 深度学习、机器学习、大数据、服务端、移动端、前端、爬虫(go、scala、Java、flutter、Python、react、Vue)等。</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">67</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">7</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="https://github.com/qq1074123922" title="GitHub &rarr; https://github.com/qq1074123922" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
    
      <span class="links-of-author-item">
      
      
        
      
      
        
      
        <a href="/1074123922@qq.com" title="E-Mail &rarr; 1074123922@qq.com"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
    
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">AILab-aida</span>
</div>
  <div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Pisces</a> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  <script src="/lib/pjax/pjax.min.js?v=0.2.8"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>
  <script>
var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[pjax], script#page-configurations, #pjax script').forEach(element => {
    var id = element.id || '';
    var src = element.src || '';
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (id !=='') {
      script.id = element.id;
    }
    if (src !== '') {
      script.src = src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});
</script>




  








  <script src="/js/local-search.js?v=7.4.0"></script>













    <div id="pjax">

  

  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: 'a6d340a24e0f5044ffc3',
      clientSecret: 'edff6432acd3e21caff2696cc123e15b3ca3461c',
      repo: 'ailab-aida.github.io',
      owner: 'AILab-aida',
      admin: ['ailab'],
      id: '740f5c0aff6998914a1e5e0906a45634',
        language: 'zh-CN',
      
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

    </div>
</body>
</html>
